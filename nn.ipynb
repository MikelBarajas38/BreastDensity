{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Networks\n",
    "\n",
    "Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:43:22.085649: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 17:43:22.088922: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 17:43:22.135009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 17:43:23.037393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = 'dataset/density_info.csv'\n",
    "dataset_path = 'dataset/GLCM/GLCM_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv(annotations_path)\n",
    "glcm_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>image_path</th>\n",
       "      <th>SeriesDescription</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image view</th>\n",
       "      <th>breast density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.239949064412092068706...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.239949...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00017</td>\n",
       "      <td>MLO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.397840223011442643919...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.397840...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00238</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.204033481911004862841...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.204033...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00699</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.179488205110519665924...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.179488...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_01617</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.151178406511629586605...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.151178...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00464</td>\n",
       "      <td>MLO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>3281</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.206174998211439771426...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.206174...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00322</td>\n",
       "      <td>MLO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>3282</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.211427675111583558805...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.211427...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00019</td>\n",
       "      <td>MLO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>3283</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.529156274123405251229...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.529156...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_01040</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>3284</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.744141121110160190397...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.744141...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_01462</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>3285</td>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.273069912411350419938...</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.273069...</td>\n",
       "      <td>full mammogram images</td>\n",
       "      <td>P_00523</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3286 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          file_path  \\\n",
       "0        0  1.3.6.1.4.1.9590.100.1.2.239949064412092068706...   \n",
       "1        1  1.3.6.1.4.1.9590.100.1.2.397840223011442643919...   \n",
       "2        2  1.3.6.1.4.1.9590.100.1.2.204033481911004862841...   \n",
       "3        3  1.3.6.1.4.1.9590.100.1.2.179488205110519665924...   \n",
       "4        4  1.3.6.1.4.1.9590.100.1.2.151178406511629586605...   \n",
       "...    ...                                                ...   \n",
       "3281  3281  1.3.6.1.4.1.9590.100.1.2.206174998211439771426...   \n",
       "3282  3282  1.3.6.1.4.1.9590.100.1.2.211427675111583558805...   \n",
       "3283  3283  1.3.6.1.4.1.9590.100.1.2.529156274123405251229...   \n",
       "3284  3284  1.3.6.1.4.1.9590.100.1.2.744141121110160190397...   \n",
       "3285  3285  1.3.6.1.4.1.9590.100.1.2.273069912411350419938...   \n",
       "\n",
       "                                             image_path  \\\n",
       "0     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.239949...   \n",
       "1     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.397840...   \n",
       "2     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.204033...   \n",
       "3     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.179488...   \n",
       "4     CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.151178...   \n",
       "...                                                 ...   \n",
       "3281  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.206174...   \n",
       "3282  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.211427...   \n",
       "3283  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.529156...   \n",
       "3284  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.744141...   \n",
       "3285  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.273069...   \n",
       "\n",
       "          SeriesDescription patient_id image view  breast density  \n",
       "0     full mammogram images    P_00017        MLO               2  \n",
       "1     full mammogram images    P_00238         CC               3  \n",
       "2     full mammogram images    P_00699         CC               3  \n",
       "3     full mammogram images    P_01617         CC               2  \n",
       "4     full mammogram images    P_00464        MLO               3  \n",
       "...                     ...        ...        ...             ...  \n",
       "3281  full mammogram images    P_00322        MLO               2  \n",
       "3282  full mammogram images    P_00019        MLO               4  \n",
       "3283  full mammogram images    P_01040         CC               3  \n",
       "3284  full mammogram images    P_01462         CC               2  \n",
       "3285  full mammogram images    P_00523         CC               2  \n",
       "\n",
       "[3286 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>correlation_0</th>\n",
       "      <th>dissimilarity_0</th>\n",
       "      <th>homogeneity_0</th>\n",
       "      <th>contrast_0</th>\n",
       "      <th>ASM_1</th>\n",
       "      <th>correlation_1</th>\n",
       "      <th>dissimilarity_1</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_2</th>\n",
       "      <th>contrast_2</th>\n",
       "      <th>ASM_3</th>\n",
       "      <th>correlation_3</th>\n",
       "      <th>dissimilarity_3</th>\n",
       "      <th>homogeneity_3</th>\n",
       "      <th>contrast_3</th>\n",
       "      <th>entropy</th>\n",
       "      <th>view</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.239949...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.919219</td>\n",
       "      <td>19.823437</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>679.669301</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.899927</td>\n",
       "      <td>21.984344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>914.332950</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.796236</td>\n",
       "      <td>31.771795</td>\n",
       "      <td>0.036988</td>\n",
       "      <td>1712.944391</td>\n",
       "      <td>7.927204</td>\n",
       "      <td>MLO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.397840...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.932134</td>\n",
       "      <td>15.758640</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>427.249847</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.894409</td>\n",
       "      <td>19.719170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>503.003140</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.891454</td>\n",
       "      <td>20.004721</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>682.401430</td>\n",
       "      <td>7.806423</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.204033...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.958115</td>\n",
       "      <td>11.353278</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>245.717647</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>17.306974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084095</td>\n",
       "      <td>400.147105</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.920868</td>\n",
       "      <td>15.573872</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>462.302637</td>\n",
       "      <td>7.767559</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.179488...</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.913868</td>\n",
       "      <td>17.938725</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>583.519332</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.838011</td>\n",
       "      <td>24.724598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>704.519531</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.859163</td>\n",
       "      <td>22.884829</td>\n",
       "      <td>0.054682</td>\n",
       "      <td>952.034233</td>\n",
       "      <td>7.838326</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.151178...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>14.990456</td>\n",
       "      <td>0.077173</td>\n",
       "      <td>397.473300</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.917030</td>\n",
       "      <td>19.082722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>634.111167</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>24.573656</td>\n",
       "      <td>0.047939</td>\n",
       "      <td>1052.476678</td>\n",
       "      <td>7.907911</td>\n",
       "      <td>MLO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>3281</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.206174...</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.943011</td>\n",
       "      <td>15.052145</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>407.463450</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.918087</td>\n",
       "      <td>17.887443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069317</td>\n",
       "      <td>539.656740</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.876004</td>\n",
       "      <td>22.378577</td>\n",
       "      <td>0.050890</td>\n",
       "      <td>885.111065</td>\n",
       "      <td>7.863990</td>\n",
       "      <td>MLO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>3282</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.211427...</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.956561</td>\n",
       "      <td>13.679136</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>342.405300</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.926957</td>\n",
       "      <td>17.968643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067305</td>\n",
       "      <td>507.122044</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.894525</td>\n",
       "      <td>21.545790</td>\n",
       "      <td>0.053552</td>\n",
       "      <td>830.344129</td>\n",
       "      <td>7.912320</td>\n",
       "      <td>MLO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>3283</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.529156...</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.960226</td>\n",
       "      <td>13.401118</td>\n",
       "      <td>0.083634</td>\n",
       "      <td>315.865089</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.931331</td>\n",
       "      <td>17.739746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082715</td>\n",
       "      <td>316.419868</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.936280</td>\n",
       "      <td>17.020900</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>504.990204</td>\n",
       "      <td>7.918697</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>3284</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.744141...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>21.800322</td>\n",
       "      <td>0.051935</td>\n",
       "      <td>808.409482</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.814763</td>\n",
       "      <td>28.103468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049032</td>\n",
       "      <td>939.963894</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.821427</td>\n",
       "      <td>27.653856</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>1288.598847</td>\n",
       "      <td>7.861434</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>3285</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.273069...</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.931311</td>\n",
       "      <td>16.273943</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>478.977865</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>21.908466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>600.620159</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.885662</td>\n",
       "      <td>20.876248</td>\n",
       "      <td>0.057527</td>\n",
       "      <td>794.976671</td>\n",
       "      <td>7.853429</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3286 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         image_path     ASM_0  \\\n",
       "0        0  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.239949...  0.000060   \n",
       "1        1  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.397840...  0.000078   \n",
       "2        2  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.204033...  0.000113   \n",
       "3        3  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.179488...  0.000069   \n",
       "4        4  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.151178...  0.000077   \n",
       "...    ...                                                ...       ...   \n",
       "3281  3281  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.206174...  0.000079   \n",
       "3282  3282  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.211427...  0.000083   \n",
       "3283  3283  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.529156...  0.000083   \n",
       "3284  3284  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.744141...  0.000056   \n",
       "3285  3285  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.273069...  0.000074   \n",
       "\n",
       "      correlation_0  dissimilarity_0  homogeneity_0  contrast_0     ASM_1  \\\n",
       "0          0.919219        19.823437       0.058807  679.669301  0.000055   \n",
       "1          0.932134        15.758640       0.068536  427.249847  0.000064   \n",
       "2          0.958115        11.353278       0.102520  245.717647  0.000078   \n",
       "3          0.913868        17.938725       0.067583  583.519332  0.000052   \n",
       "4          0.949262        14.990456       0.077173  397.473300  0.000062   \n",
       "...             ...              ...            ...         ...       ...   \n",
       "3281       0.943011        15.052145       0.075168  407.463450  0.000068   \n",
       "3282       0.956561        13.679136       0.084714  342.405300  0.000065   \n",
       "3283       0.960226        13.401118       0.083634  315.865089  0.000065   \n",
       "3284       0.888072        21.800322       0.051935  808.409482  0.000046   \n",
       "3285       0.931311        16.273943       0.071930  478.977865  0.000057   \n",
       "\n",
       "      correlation_1  dissimilarity_1  ...  homogeneity_2  contrast_2  \\\n",
       "0          0.899927        21.984344  ...       0.051649  914.332950   \n",
       "1          0.894409        19.719170  ...       0.064644  503.003140   \n",
       "2          0.902425        17.306974  ...       0.084095  400.147105   \n",
       "3          0.838011        24.724598  ...       0.062652  704.519531   \n",
       "4          0.917030        19.082722  ...       0.062199  634.111167   \n",
       "...             ...              ...  ...            ...         ...   \n",
       "3281       0.918087        17.887443  ...       0.069317  539.656740   \n",
       "3282       0.926957        17.968643  ...       0.067305  507.122044   \n",
       "3283       0.931331        17.739746  ...       0.082715  316.419868   \n",
       "3284       0.814763        28.103468  ...       0.049032  939.963894   \n",
       "3285       0.876556        21.908466  ...       0.066618  600.620159   \n",
       "\n",
       "         ASM_3  correlation_3  dissimilarity_3  homogeneity_3   contrast_3  \\\n",
       "0     0.000041       0.796236        31.771795       0.036988  1712.944391   \n",
       "1     0.000063       0.891454        20.004721       0.054418   682.401430   \n",
       "2     0.000085       0.920868        15.573872       0.076014   462.302637   \n",
       "3     0.000056       0.859163        22.884829       0.054682   952.034233   \n",
       "4     0.000050       0.865504        24.573656       0.047939  1052.476678   \n",
       "...        ...            ...              ...            ...          ...   \n",
       "3281  0.000056       0.876004        22.378577       0.050890   885.111065   \n",
       "3282  0.000056       0.894525        21.545790       0.053552   830.344129   \n",
       "3283  0.000067       0.936280        17.020900       0.066712   504.990204   \n",
       "3284  0.000046       0.821427        27.653856       0.041327  1288.598847   \n",
       "3285  0.000060       0.885662        20.876248       0.057527   794.976671   \n",
       "\n",
       "       entropy  view  density  \n",
       "0     7.927204   MLO        2  \n",
       "1     7.806423    CC        3  \n",
       "2     7.767559    CC        3  \n",
       "3     7.838326    CC        2  \n",
       "4     7.907911   MLO        3  \n",
       "...        ...   ...      ...  \n",
       "3281  7.863990   MLO        2  \n",
       "3282  7.912320   MLO        4  \n",
       "3283  7.918697    CC        3  \n",
       "3284  7.861434    CC        2  \n",
       "3285  7.853429    CC        2  \n",
       "\n",
       "[3286 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glcm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge class 2 and 3\n",
    "glcm_df['density'] = glcm_df['density'].replace(3, 2)\n",
    "glcm_df['density'] = glcm_df['density'] - 1\n",
    "glcm_df['density'] = glcm_df['density'].replace(3, 2)\n",
    "\n",
    "# undersample the majority class\n",
    "# n = 1500\n",
    "# glcm_df = glcm_df.drop(glcm_df[glcm_df['density'] == 1].sample(n = n, random_state=1).index)\n",
    "\n",
    "# drop non-feature columns\n",
    "glcm_df = glcm_df.drop(columns=['id', 'image_path', 'view'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>correlation_0</th>\n",
       "      <th>dissimilarity_0</th>\n",
       "      <th>homogeneity_0</th>\n",
       "      <th>contrast_0</th>\n",
       "      <th>ASM_1</th>\n",
       "      <th>correlation_1</th>\n",
       "      <th>dissimilarity_1</th>\n",
       "      <th>homogeneity_1</th>\n",
       "      <th>contrast_1</th>\n",
       "      <th>...</th>\n",
       "      <th>dissimilarity_2</th>\n",
       "      <th>homogeneity_2</th>\n",
       "      <th>contrast_2</th>\n",
       "      <th>ASM_3</th>\n",
       "      <th>correlation_3</th>\n",
       "      <th>dissimilarity_3</th>\n",
       "      <th>homogeneity_3</th>\n",
       "      <th>contrast_3</th>\n",
       "      <th>entropy</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.919219</td>\n",
       "      <td>19.823437</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>679.669301</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.899927</td>\n",
       "      <td>21.984344</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>841.248012</td>\n",
       "      <td>...</td>\n",
       "      <td>23.044133</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>914.332950</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.796236</td>\n",
       "      <td>31.771795</td>\n",
       "      <td>0.036988</td>\n",
       "      <td>1712.944391</td>\n",
       "      <td>7.927204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.932134</td>\n",
       "      <td>15.758640</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>427.249847</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.894409</td>\n",
       "      <td>19.719170</td>\n",
       "      <td>0.054698</td>\n",
       "      <td>663.816917</td>\n",
       "      <td>...</td>\n",
       "      <td>17.110340</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>503.003140</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.891454</td>\n",
       "      <td>20.004721</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>682.401430</td>\n",
       "      <td>7.806423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.958115</td>\n",
       "      <td>11.353278</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>245.717647</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>17.306974</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>570.055486</td>\n",
       "      <td>...</td>\n",
       "      <td>14.369378</td>\n",
       "      <td>0.084095</td>\n",
       "      <td>400.147105</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.920868</td>\n",
       "      <td>15.573872</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>462.302637</td>\n",
       "      <td>7.767559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.913868</td>\n",
       "      <td>17.938725</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>583.519332</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.838011</td>\n",
       "      <td>24.724598</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>1095.025559</td>\n",
       "      <td>...</td>\n",
       "      <td>19.626210</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>704.519531</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.859163</td>\n",
       "      <td>22.884829</td>\n",
       "      <td>0.054682</td>\n",
       "      <td>952.034233</td>\n",
       "      <td>7.838326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>14.990456</td>\n",
       "      <td>0.077173</td>\n",
       "      <td>397.473300</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.917030</td>\n",
       "      <td>19.082722</td>\n",
       "      <td>0.060307</td>\n",
       "      <td>649.260346</td>\n",
       "      <td>...</td>\n",
       "      <td>18.922013</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>634.111167</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>24.573656</td>\n",
       "      <td>0.047939</td>\n",
       "      <td>1052.476678</td>\n",
       "      <td>7.907911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.943011</td>\n",
       "      <td>15.052145</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>407.463450</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.918087</td>\n",
       "      <td>17.887443</td>\n",
       "      <td>0.066273</td>\n",
       "      <td>584.687566</td>\n",
       "      <td>...</td>\n",
       "      <td>17.216268</td>\n",
       "      <td>0.069317</td>\n",
       "      <td>539.656740</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.876004</td>\n",
       "      <td>22.378577</td>\n",
       "      <td>0.050890</td>\n",
       "      <td>885.111065</td>\n",
       "      <td>7.863990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.956561</td>\n",
       "      <td>13.679136</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>342.405300</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.926957</td>\n",
       "      <td>17.968643</td>\n",
       "      <td>0.064967</td>\n",
       "      <td>575.042599</td>\n",
       "      <td>...</td>\n",
       "      <td>16.846768</td>\n",
       "      <td>0.067305</td>\n",
       "      <td>507.122044</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.894525</td>\n",
       "      <td>21.545790</td>\n",
       "      <td>0.053552</td>\n",
       "      <td>830.344129</td>\n",
       "      <td>7.912320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.960226</td>\n",
       "      <td>13.401118</td>\n",
       "      <td>0.083634</td>\n",
       "      <td>315.865089</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.931331</td>\n",
       "      <td>17.739746</td>\n",
       "      <td>0.063561</td>\n",
       "      <td>544.215317</td>\n",
       "      <td>...</td>\n",
       "      <td>13.476149</td>\n",
       "      <td>0.082715</td>\n",
       "      <td>316.419868</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.936280</td>\n",
       "      <td>17.020900</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>504.990204</td>\n",
       "      <td>7.918697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>21.800322</td>\n",
       "      <td>0.051935</td>\n",
       "      <td>808.409482</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.814763</td>\n",
       "      <td>28.103468</td>\n",
       "      <td>0.040864</td>\n",
       "      <td>1336.694225</td>\n",
       "      <td>...</td>\n",
       "      <td>23.538710</td>\n",
       "      <td>0.049032</td>\n",
       "      <td>939.963894</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.821427</td>\n",
       "      <td>27.653856</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>1288.598847</td>\n",
       "      <td>7.861434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.931311</td>\n",
       "      <td>16.273943</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>478.977865</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>21.908466</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>858.286259</td>\n",
       "      <td>...</td>\n",
       "      <td>18.104381</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>600.620159</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.885662</td>\n",
       "      <td>20.876248</td>\n",
       "      <td>0.057527</td>\n",
       "      <td>794.976671</td>\n",
       "      <td>7.853429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3286 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASM_0  correlation_0  dissimilarity_0  homogeneity_0  contrast_0  \\\n",
       "0     0.000060       0.919219        19.823437       0.058807  679.669301   \n",
       "1     0.000078       0.932134        15.758640       0.068536  427.249847   \n",
       "2     0.000113       0.958115        11.353278       0.102520  245.717647   \n",
       "3     0.000069       0.913868        17.938725       0.067583  583.519332   \n",
       "4     0.000077       0.949262        14.990456       0.077173  397.473300   \n",
       "...        ...            ...              ...            ...         ...   \n",
       "3281  0.000079       0.943011        15.052145       0.075168  407.463450   \n",
       "3282  0.000083       0.956561        13.679136       0.084714  342.405300   \n",
       "3283  0.000083       0.960226        13.401118       0.083634  315.865089   \n",
       "3284  0.000056       0.888072        21.800322       0.051935  808.409482   \n",
       "3285  0.000074       0.931311        16.273943       0.071930  478.977865   \n",
       "\n",
       "         ASM_1  correlation_1  dissimilarity_1  homogeneity_1   contrast_1  \\\n",
       "0     0.000055       0.899927        21.984344       0.054299   841.248012   \n",
       "1     0.000064       0.894409        19.719170       0.054698   663.816917   \n",
       "2     0.000078       0.902425        17.306974       0.068856   570.055486   \n",
       "3     0.000052       0.838011        24.724598       0.049348  1095.025559   \n",
       "4     0.000062       0.917030        19.082722       0.060307   649.260346   \n",
       "...        ...            ...              ...            ...          ...   \n",
       "3281  0.000068       0.918087        17.887443       0.066273   584.687566   \n",
       "3282  0.000065       0.926957        17.968643       0.064967   575.042599   \n",
       "3283  0.000065       0.931331        17.739746       0.063561   544.215317   \n",
       "3284  0.000046       0.814763        28.103468       0.040864  1336.694225   \n",
       "3285  0.000057       0.876556        21.908466       0.053419   858.286259   \n",
       "\n",
       "      ...  dissimilarity_2  homogeneity_2  contrast_2     ASM_3  \\\n",
       "0     ...        23.044133       0.051649  914.332950  0.000041   \n",
       "1     ...        17.110340       0.064644  503.003140  0.000063   \n",
       "2     ...        14.369378       0.084095  400.147105  0.000085   \n",
       "3     ...        19.626210       0.062652  704.519531  0.000056   \n",
       "4     ...        18.922013       0.062199  634.111167  0.000050   \n",
       "...   ...              ...            ...         ...       ...   \n",
       "3281  ...        17.216268       0.069317  539.656740  0.000056   \n",
       "3282  ...        16.846768       0.067305  507.122044  0.000056   \n",
       "3283  ...        13.476149       0.082715  316.419868  0.000067   \n",
       "3284  ...        23.538710       0.049032  939.963894  0.000046   \n",
       "3285  ...        18.104381       0.066618  600.620159  0.000060   \n",
       "\n",
       "      correlation_3  dissimilarity_3  homogeneity_3   contrast_3   entropy  \\\n",
       "0          0.796236        31.771795       0.036988  1712.944391  7.927204   \n",
       "1          0.891454        20.004721       0.054418   682.401430  7.806423   \n",
       "2          0.920868        15.573872       0.076014   462.302637  7.767559   \n",
       "3          0.859163        22.884829       0.054682   952.034233  7.838326   \n",
       "4          0.865504        24.573656       0.047939  1052.476678  7.907911   \n",
       "...             ...              ...            ...          ...       ...   \n",
       "3281       0.876004        22.378577       0.050890   885.111065  7.863990   \n",
       "3282       0.894525        21.545790       0.053552   830.344129  7.912320   \n",
       "3283       0.936280        17.020900       0.066712   504.990204  7.918697   \n",
       "3284       0.821427        27.653856       0.041327  1288.598847  7.861434   \n",
       "3285       0.885662        20.876248       0.057527   794.976671  7.853429   \n",
       "\n",
       "      density  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3281        1  \n",
       "3282        2  \n",
       "3283        1  \n",
       "3284        1  \n",
       "3285        1  \n",
       "\n",
       "[3286 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glcm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: [1 0 2]\n",
      "class A (0) count: 516\n",
      "class B + C (1) count: 2281\n",
      "class D (2) count: 489\n"
     ]
    }
   ],
   "source": [
    "glcm_df['density'].value_counts().sort_index().plot(kind='bar')\n",
    "\n",
    "plt.title('Density histogram')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'classes: {glcm_df[\"density\"].unique()}')\n",
    "print(f'class A (0) count: {len(glcm_df[glcm_df[\"density\"] == 0])}')\n",
    "print(f'class B + C (1) count: {len(glcm_df[glcm_df[\"density\"] == 1])}')\n",
    "print(f'class D (2) count: {len(glcm_df[glcm_df[\"density\"] == 2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'class B (1) count: {len(glcm_df[glcm_df[\"density\"] == 1])}')\n",
    "print(f'class C (2) count: {len(glcm_df[glcm_df[\"density\"] == 2])}')\n",
    "print(f'class D (3) count: {len(glcm_df[glcm_df[\"density\"] == 3])}')X = glcm_df.drop(columns=['density'])\n",
    "y = glcm_df['density']\n",
    "\n",
    "input_size = X.shape[1]\n",
    "output_size = len(y.unique())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_size,), name='input'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(rate = 0.25),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(rate = 0.10),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(rate = 0.05),\n",
    "        Dense(output_size, activation='softmax', name='density')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikel/code/BreastDensity/env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ density (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ density (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,411</span> (68.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,411\u001b[0m (68.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,411</span> (68.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,411\u001b[0m (68.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Training (80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4296 - loss: 32.5253 - val_accuracy: 0.7052 - val_loss: 5.3135\n",
      "Epoch 2/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 6.7882 - val_accuracy: 0.6368 - val_loss: 1.3409\n",
      "Epoch 3/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5081 - loss: 2.5939 - val_accuracy: 0.7006 - val_loss: 0.9122\n",
      "Epoch 4/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 1.3545 - val_accuracy: 0.7067 - val_loss: 0.8991\n",
      "Epoch 5/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 0.9546 - val_accuracy: 0.7036 - val_loss: 0.8536\n",
      "Epoch 6/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6726 - loss: 0.8982 - val_accuracy: 0.7082 - val_loss: 0.8232\n",
      "Epoch 7/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 0.8877 - val_accuracy: 0.7036 - val_loss: 0.8540\n",
      "Epoch 8/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.8810 - val_accuracy: 0.7052 - val_loss: 0.8145\n",
      "Epoch 9/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: 0.8593 - val_accuracy: 0.7052 - val_loss: 0.8161\n",
      "Epoch 10/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.8526 - val_accuracy: 0.7052 - val_loss: 0.8371\n",
      "Epoch 11/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8406 - val_accuracy: 0.7052 - val_loss: 0.8082\n",
      "Epoch 12/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.8448 - val_accuracy: 0.7052 - val_loss: 0.7992\n",
      "Epoch 13/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8175 - val_accuracy: 0.7021 - val_loss: 0.8156\n",
      "Epoch 14/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8272 - val_accuracy: 0.7052 - val_loss: 0.8017\n",
      "Epoch 15/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8042\n",
      "Epoch 16/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8257 - val_accuracy: 0.7052 - val_loss: 0.8034\n",
      "Epoch 17/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.8162 - val_accuracy: 0.7052 - val_loss: 0.8088\n",
      "Epoch 18/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.8259 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 19/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.8531 - val_accuracy: 0.7052 - val_loss: 0.7932\n",
      "Epoch 20/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6821 - loss: 0.8383 - val_accuracy: 0.7021 - val_loss: 0.8059\n",
      "Epoch 21/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8274 - val_accuracy: 0.7052 - val_loss: 0.7926\n",
      "Epoch 22/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.8256 - val_accuracy: 0.7052 - val_loss: 0.8066\n",
      "Epoch 23/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8139 - val_accuracy: 0.7052 - val_loss: 0.8072\n",
      "Epoch 24/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8105\n",
      "Epoch 25/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.8254 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 26/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.8305 - val_accuracy: 0.7052 - val_loss: 0.7956\n",
      "Epoch 27/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.8144 - val_accuracy: 0.7067 - val_loss: 0.7941\n",
      "Epoch 28/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.7897\n",
      "Epoch 29/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.7983 - val_accuracy: 0.7052 - val_loss: 0.7902\n",
      "Epoch 30/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.7836 - val_accuracy: 0.7052 - val_loss: 0.7882\n",
      "Epoch 31/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.7935 - val_accuracy: 0.7036 - val_loss: 0.7897\n",
      "Epoch 32/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8241 - val_accuracy: 0.7082 - val_loss: 0.7872\n",
      "Epoch 33/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.8100 - val_accuracy: 0.7052 - val_loss: 0.8024\n",
      "Epoch 34/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.8297 - val_accuracy: 0.7052 - val_loss: 0.8040\n",
      "Epoch 35/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6890 - loss: 0.8261 - val_accuracy: 0.7052 - val_loss: 0.7922\n",
      "Epoch 36/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6882 - loss: 0.8269 - val_accuracy: 0.7052 - val_loss: 0.8083\n",
      "Epoch 37/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.7844\n",
      "Epoch 38/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6894 - loss: 0.8214 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 39/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8093 - val_accuracy: 0.7036 - val_loss: 0.7879\n",
      "Epoch 40/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.8148 - val_accuracy: 0.7021 - val_loss: 0.7835\n",
      "Epoch 41/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6981 - loss: 0.8114 - val_accuracy: 0.7082 - val_loss: 0.7831\n",
      "Epoch 42/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8281 - val_accuracy: 0.7052 - val_loss: 0.7804\n",
      "Epoch 43/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.8019 - val_accuracy: 0.6991 - val_loss: 0.7855\n",
      "Epoch 44/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.8102 - val_accuracy: 0.7036 - val_loss: 0.7825\n",
      "Epoch 45/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: 0.8205 - val_accuracy: 0.7052 - val_loss: 0.8065\n",
      "Epoch 46/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8084 - val_accuracy: 0.7067 - val_loss: 0.7840\n",
      "Epoch 47/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.8131 - val_accuracy: 0.7052 - val_loss: 0.7952\n",
      "Epoch 48/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.8168 - val_accuracy: 0.7052 - val_loss: 0.8103\n",
      "Epoch 49/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.8360 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 50/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6797 - loss: 0.8472 - val_accuracy: 0.7052 - val_loss: 0.7852\n",
      "Epoch 51/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8087 - val_accuracy: 0.7052 - val_loss: 0.7841\n",
      "Epoch 52/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8272 - val_accuracy: 0.7067 - val_loss: 0.7840\n",
      "Epoch 53/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6894 - loss: 0.8219 - val_accuracy: 0.7036 - val_loss: 0.7917\n",
      "Epoch 54/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.8276 - val_accuracy: 0.7006 - val_loss: 0.7826\n",
      "Epoch 55/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 0.8138 - val_accuracy: 0.7067 - val_loss: 0.7804\n",
      "Epoch 56/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.8032 - val_accuracy: 0.7006 - val_loss: 0.7774\n",
      "Epoch 57/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.8113 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 58/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.8115 - val_accuracy: 0.7052 - val_loss: 0.8105\n",
      "Epoch 59/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6846 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 60/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6894 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8097\n",
      "Epoch 61/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.8267 - val_accuracy: 0.7052 - val_loss: 0.8053\n",
      "Epoch 62/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.8215 - val_accuracy: 0.6733 - val_loss: 0.8119\n",
      "Epoch 63/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.8335 - val_accuracy: 0.7052 - val_loss: 0.8103\n",
      "Epoch 64/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6975 - loss: 0.8253 - val_accuracy: 0.7052 - val_loss: 0.8102\n",
      "Epoch 65/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8224 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 66/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 67/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.8196 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 68/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 69/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8420 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 70/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 0.8517 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 71/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 72/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.8331 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 73/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.8269 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 74/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8309 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 75/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 76/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.8309 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 77/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 78/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 79/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 80/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6974 - loss: 0.8233 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 81/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.8275 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 82/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.8327 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 83/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8411 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 84/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.8374 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 85/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8128 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 86/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.8470 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 87/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 88/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 89/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6819 - loss: 0.8466 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 90/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 91/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.8203 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 92/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.8079 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 93/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.8257 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 94/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.8184 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 95/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6857 - loss: 0.8414 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 96/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.8282 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 97/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6880 - loss: 0.8389 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 98/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8435 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 99/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.8483 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 100/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6890 - loss: 0.8384 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 101/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8232 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 102/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6872 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 103/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.8423 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 104/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.8490 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 105/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 106/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8278 - val_accuracy: 0.7052 - val_loss: 0.8104\n",
      "Epoch 107/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 108/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.8097 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 109/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.8259 - val_accuracy: 0.7052 - val_loss: 0.8100\n",
      "Epoch 110/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 111/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 112/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.8163 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 113/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.8455 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 114/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6940 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 115/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8183 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 116/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.8256 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 117/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6774 - loss: 0.8534 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 118/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 119/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.8452 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 120/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.8248 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 121/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6865 - loss: 0.8395 - val_accuracy: 0.7052 - val_loss: 0.8116\n",
      "Epoch 122/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.8554 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 123/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 0.8332 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 124/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7002 - loss: 0.8181 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 125/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 126/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8190 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 127/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.8554 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 128/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8285 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 129/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.8273 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 130/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.7957 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 131/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6949 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 132/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8236 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 133/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.8321 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 134/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 135/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 136/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8103 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 137/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.8198 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 138/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 139/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.8288 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 140/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.8245 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 141/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6794 - loss: 0.8497 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 142/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8335 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 143/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6920 - loss: 0.8347 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 144/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.8299 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 145/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.8297 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 146/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 147/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 148/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.8203 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 149/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8260 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 150/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8362 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 151/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8163 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 152/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6893 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 153/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6843 - loss: 0.8417 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 154/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8060 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 155/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6747 - loss: 0.8581 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 156/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8234 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 157/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8217 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 158/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.8187 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 159/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.8526 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 160/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.8335 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 161/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.8310 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 162/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 0.8286 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 163/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.8444 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 164/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 165/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 166/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6816 - loss: 0.8466 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 167/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8272 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 168/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.8575 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 169/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.8302 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 170/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: 0.8325 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 171/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 172/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6886 - loss: 0.8372 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 173/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.8425 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 174/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8326 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 175/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6894 - loss: 0.8358 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 176/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8332 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 177/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - loss: 0.8224 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 178/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.8137 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 179/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6890 - loss: 0.8362 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 180/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8270 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 181/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.8237 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 182/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 183/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 184/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.8360 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 185/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.8258 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 186/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6744 - loss: 0.8595 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 187/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8301 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 188/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 189/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 190/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6885 - loss: 0.8368 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 191/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 192/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.8333 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 193/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.8185 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 194/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 195/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.8522 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 196/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.8151 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 197/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.8327 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 198/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 0.8550 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 199/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.8516 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 200/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6881 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 201/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.8526 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 202/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8165 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 203/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 204/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 205/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.8504 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 206/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 207/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.8460 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 208/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6809 - loss: 0.8498 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 209/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.8077 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 210/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7009 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 211/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.8398 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 212/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.8124 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 213/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6846 - loss: 0.8436 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 214/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: 0.8450 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 215/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.8239 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 216/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 217/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.8139 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 218/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8317 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 219/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - loss: 0.8362 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 220/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.8430 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 221/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 222/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.8273 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 223/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6913 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 224/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 225/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8255 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 226/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8260 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 227/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 0.8233 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 228/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6999 - loss: 0.8207 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 229/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8268 - val_accuracy: 0.7052 - val_loss: 0.8116\n",
      "Epoch 230/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 231/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6964 - loss: 0.8258 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 232/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 233/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.8454 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 234/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.8153 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 235/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.8440 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 236/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.8172 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 237/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 238/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.8240 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 239/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.8181 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 240/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7027 - loss: 0.8158 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 241/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.8204 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 242/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.8449 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 243/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6804 - loss: 0.8497 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 244/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.8363 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 245/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6819 - loss: 0.8479 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 246/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.8353 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 247/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 248/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.8224 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 249/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.8222 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 250/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7057 - loss: 0.8107 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 251/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 252/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 253/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6994 - loss: 0.8214 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 254/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6861 - loss: 0.8415 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 255/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.8110 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 256/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 257/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 258/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.8309 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 259/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8316 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 260/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.8422 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 261/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - loss: 0.8229 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 262/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.8443 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 263/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.8316 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 264/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 265/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6655 - loss: 0.8713 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 266/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 267/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6931 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 268/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8324 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 269/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6902 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 270/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6748 - loss: 0.8561 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 271/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 272/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8321 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 273/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.8376 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 274/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8262 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 275/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 276/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.8461 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 277/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.8565 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 278/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8380 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 279/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8327 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 280/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8305 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 281/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.8188 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 282/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.8029 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 283/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.8313 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 284/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 285/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6936 - loss: 0.8290 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 286/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.8481 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 287/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8337 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 288/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8150 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 289/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 290/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8392 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 291/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.8414 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 292/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7042 - loss: 0.8123 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 293/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 294/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6922 - loss: 0.8321 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 295/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 296/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8328 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 297/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.8298 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 298/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.8112 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 299/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 0.8438 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 300/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.8335 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 301/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.8091 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 302/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.8330 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 303/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.8299 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 304/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 305/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 306/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 307/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 308/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 0.8473 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 309/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 310/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8243 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 311/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.8281 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 312/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8406 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 313/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.8247 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 314/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.8759 - val_accuracy: 0.7052 - val_loss: 0.8116\n",
      "Epoch 315/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6873 - loss: 0.8381 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 316/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 317/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.8458 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 318/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.8246 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 319/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.8101 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 320/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.8355 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 321/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.8214 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 322/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.8368 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 323/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.8450 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 324/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.8487 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 325/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 0.8217 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 326/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 327/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 328/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.8186 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 329/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6820 - loss: 0.8474 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 330/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7113 - loss: 0.8040 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 331/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.8203 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 332/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.8162 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 333/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7021 - loss: 0.8163 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 334/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6786 - loss: 0.8516 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 335/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6647 - loss: 0.8711 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 336/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8393 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 337/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6720 - loss: 0.8624 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 338/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6859 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 339/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.8503 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 340/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6818 - loss: 0.8469 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 341/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 342/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.8138 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 343/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.8085 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 344/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 0.8313 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 345/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6951 - loss: 0.8266 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 346/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.8356 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 347/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.8224 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 348/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.8220 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 349/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.8197 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 350/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6796 - loss: 0.8495 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 351/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.8311 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 352/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.8474 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 353/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.8228 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 354/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.8324 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 355/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.8566 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 356/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8283 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 357/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6828 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 358/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.8476 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 359/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.8233 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 360/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.8430 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 361/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 362/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8377 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 363/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.8564 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 364/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.8335 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 365/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 366/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.8522 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 367/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8300 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 368/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8288 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 369/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.8500 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 370/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8322 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 371/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6868 - loss: 0.8381 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 372/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6811 - loss: 0.8483 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 373/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.8152 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 374/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8441 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 375/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.8200 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 376/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 377/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.8443 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 378/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6771 - loss: 0.8546 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 379/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 0.8457 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 380/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6906 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 381/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 0.8461 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 382/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.8412 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 383/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8256 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 384/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.8276 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 385/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.8325 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 386/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 387/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.8393 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 388/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.8195 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 389/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.8463 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 390/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.8280 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 391/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 392/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.8294 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 393/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6942 - loss: 0.8276 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 394/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8275 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 395/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8297 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 396/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8221 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 397/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6933 - loss: 0.8306 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 398/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.8211 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 399/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6819 - loss: 0.8464 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 400/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 401/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6966 - loss: 0.8237 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 402/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 403/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6805 - loss: 0.8476 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 404/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6899 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 405/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 406/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.8207 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 407/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6855 - loss: 0.8405 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 408/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 409/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6994 - loss: 0.8210 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 410/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 0.8343 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 411/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8379 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 412/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6943 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 413/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.8218 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 414/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.8313 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 415/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 416/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 417/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8367 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 418/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.8410 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 419/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 420/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.8196 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 421/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8257 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 422/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8234 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 423/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8247 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 424/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8096 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 425/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.8208 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 426/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.8454 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 427/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 0.8472 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 428/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.8432 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 429/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.8201 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 430/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 431/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.8135 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 432/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.8336 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 433/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.8226 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 434/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6974 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 435/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.8268 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 436/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6884 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 437/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 0.8066 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 438/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.8380 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 439/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6879 - loss: 0.8375 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 440/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6948 - loss: 0.8284 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 441/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.8446 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 442/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.8274 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 443/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.8431 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 444/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6994 - loss: 0.8202 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 445/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.8255 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 446/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.8166 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 447/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.8306 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 448/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.8438 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 449/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.8152 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 450/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.8213 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 451/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.8282 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 452/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6999 - loss: 0.8203 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 453/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6968 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 454/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8346 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 455/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.8442 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 456/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6868 - loss: 0.8395 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 457/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.8353 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 458/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.8317 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 459/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 460/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.8440 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 461/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 462/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.8332 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 463/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.8089 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 464/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.8146 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 465/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7041 - loss: 0.8126 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 466/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 467/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 468/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.8482 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 469/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.8172 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 470/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.8385 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 471/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8306 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 472/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.8188 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 473/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7092 - loss: 0.8048 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 474/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8374 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 475/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6917 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 476/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.8310 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 477/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8222 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 478/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.8453 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 479/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 480/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 481/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.8277 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 482/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 483/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6808 - loss: 0.8486 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 484/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.8231 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 485/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8345 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 486/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.8154 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 487/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.8479 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 488/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6974 - loss: 0.8232 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 489/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.8452 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 490/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6777 - loss: 0.8535 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 491/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6942 - loss: 0.8275 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 492/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7046 - loss: 0.8122 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 493/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.8270 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 494/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7043 - loss: 0.8126 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 495/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6871 - loss: 0.8379 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 496/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6926 - loss: 0.8310 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 497/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8090 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 498/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.8315 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 499/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.8214 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 500/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 501/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.8403 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 502/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.8434 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 503/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7021 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 504/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.8597 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 505/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8394 - val_accuracy: 0.7052 - val_loss: 0.8106\n",
      "Epoch 506/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.8477 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 507/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6831 - loss: 0.8450 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 508/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.8403 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 509/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.8377 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 510/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.8211 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 511/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.8138 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 512/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.8484 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 513/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 514/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6894 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 515/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.8339 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 516/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.8245 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 517/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.8323 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 518/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.8168 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 519/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.8364 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 520/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 0.8216 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 521/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.8306 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 522/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8381 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 523/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8251 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 524/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8265 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 525/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 526/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.8320 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 527/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.8434 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 528/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.8211 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 529/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 530/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.8142 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 531/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6794 - loss: 0.8503 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 532/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8371 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 533/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.7983 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 534/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6926 - loss: 0.8301 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 535/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 536/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.8275 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 537/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 538/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: 0.8065 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 539/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.8206 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 540/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.8554 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 541/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6906 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 542/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.7955 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 543/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.8537 - val_accuracy: 0.7052 - val_loss: 0.8117\n",
      "Epoch 544/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7033 - loss: 0.8150 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 545/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 546/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6859 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 547/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.8166 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 548/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8270 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 549/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7048 - loss: 0.8121 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 550/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6831 - loss: 0.8457 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 551/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8220 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 552/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 0.8513 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 553/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.8205 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 554/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7051 - loss: 0.8113 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 555/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.8242 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 556/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 557/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8379 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 558/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6758 - loss: 0.8542 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 559/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8393 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 560/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8248 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 561/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6968 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 562/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8285 - val_accuracy: 0.7052 - val_loss: 0.8116\n",
      "Epoch 563/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.8623 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 564/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.8203 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 565/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6825 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 566/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 567/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6815 - loss: 0.8479 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 568/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6936 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 569/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 570/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8279 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 571/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 572/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7054 - loss: 0.8114 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 573/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6791 - loss: 0.8498 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 574/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6983 - loss: 0.8223 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 575/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6980 - loss: 0.8232 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 576/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7060 - loss: 0.8101 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 577/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.8294 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 578/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6852 - loss: 0.8409 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 579/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.8242 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 580/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 0.8259 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 581/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8311 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 582/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.8216 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 583/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6826 - loss: 0.8450 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 584/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.8435 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 585/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 586/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8320 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 587/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 588/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7007 - loss: 0.8180 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 589/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.8421 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 590/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 591/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6959 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 592/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.8174 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 593/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6760 - loss: 0.8564 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 594/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.8267 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 595/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.8281 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 596/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 597/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 598/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 599/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6846 - loss: 0.8416 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 600/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 601/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8102 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 602/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8286 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 603/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 604/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.8419 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 605/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.8198 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 606/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: 0.8316 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 607/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.8384 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 608/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.8301 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 609/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.8533 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 610/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8195 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 611/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.8228 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 612/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.8291 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 613/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8309 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 614/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8282 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 615/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8379 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 616/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 617/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 618/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 619/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8251 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 620/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.8426 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 621/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.8198 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 622/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.8231 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 623/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8422 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 624/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.8401 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 625/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6961 - loss: 0.8248 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 626/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.8256 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 627/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 628/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.8212 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 629/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 630/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - loss: 0.8355 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 631/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 632/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.8298 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 633/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.8228 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 634/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8325 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 635/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 636/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6849 - loss: 0.8411 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 637/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.8409 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 638/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7042 - loss: 0.8139 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 639/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8240 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 640/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6868 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 641/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.8423 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 642/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6968 - loss: 0.8229 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 643/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.8474 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 644/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.8458 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 645/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7075 - loss: 0.8078 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 646/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 647/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.8394 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 648/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 0.8254 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 649/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8345 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 650/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6894 - loss: 0.8344 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 651/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.8501 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 652/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8239 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 653/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.8271 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 654/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8236 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 655/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.8269 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 656/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8260 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 657/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 658/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8344 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 659/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 660/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.8126 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 661/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 662/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 663/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.8330 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 664/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6763 - loss: 0.8548 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 665/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6846 - loss: 0.8419 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 666/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 667/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 668/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6843 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 669/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.8546 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 670/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.8095 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 671/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.8584 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 672/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 673/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8272 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 674/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6826 - loss: 0.8455 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 675/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8261 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 676/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 0.8423 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 677/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.8296 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 678/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.8228 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 679/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.8262 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 680/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.8508 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 681/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.8262 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 682/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 0.8178 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 683/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.8017 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 684/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.8261 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 685/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 686/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8320 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 687/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8382 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 688/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8354 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 689/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6970 - loss: 0.8245 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 690/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.8184 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 691/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8360 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 692/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.8466 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 693/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8094 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 694/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 0.8300 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 695/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 0.8298 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 696/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 697/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8254 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 698/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 699/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.8664 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 700/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.8377 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 701/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6810 - loss: 0.8479 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 702/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6888 - loss: 0.8360 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 703/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 704/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8339 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 705/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.8354 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 706/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 707/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 708/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7000 - loss: 0.8199 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 709/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6961 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 710/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.8092 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 711/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6996 - loss: 0.8201 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 712/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 0.8361 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 713/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6967 - loss: 0.8233 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 714/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 715/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7009 - loss: 0.8181 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 716/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 717/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6859 - loss: 0.8398 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 718/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6827 - loss: 0.8444 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 719/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 0.8368 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 720/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.8221 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 721/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 722/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.8187 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 723/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6923 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 724/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 725/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6879 - loss: 0.8376 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 726/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.8192 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 727/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8331 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 728/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.8143 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 729/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.8158 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 730/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.8394 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 731/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8343 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 732/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8374 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 733/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.8143 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 734/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.8243 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 735/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.8429 - val_accuracy: 0.7052 - val_loss: 0.8115\n",
      "Epoch 736/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.8161 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 737/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.8235 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 738/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 739/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.8459 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 740/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6846 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 741/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 742/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.8300 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 743/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 0.8220 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 744/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6942 - loss: 0.8273 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 745/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 746/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.8127 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 747/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8299 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 748/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: 0.8315 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 749/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 0.8212 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 750/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.8486 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 751/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 752/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 753/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.8448 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 754/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6931 - loss: 0.8296 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 755/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.8348 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 756/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8344 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 757/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: 0.8064 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 758/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.8147 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 759/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 760/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.8198 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 761/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.8417 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 762/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6871 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 763/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6802 - loss: 0.8490 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 764/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7048 - loss: 0.8120 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 765/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6865 - loss: 0.8402 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 766/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6907 - loss: 0.8324 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 767/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 768/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.8269 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 769/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.8427 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 770/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.8413 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 771/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 772/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.8114 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 773/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 774/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.8473 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 775/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.8405 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 776/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 777/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6762 - loss: 0.8548 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 778/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6923 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 779/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7005 - loss: 0.8184 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 780/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.8202 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 781/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6966 - loss: 0.8248 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 782/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6906 - loss: 0.8336 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 783/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8318 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 784/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 785/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.8105 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 786/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.8507 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 787/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 0.8303 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 788/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 789/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 790/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 791/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6855 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 792/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.8369 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 793/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.8162 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 794/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.8149 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 795/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 796/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.8215 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 797/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.8307 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 798/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.8199 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 799/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8296 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 800/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8393 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 801/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.8325 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 802/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6938 - loss: 0.8290 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 803/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8392 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 804/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.8163 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 805/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.8270 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 806/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.8267 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 807/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6949 - loss: 0.8270 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 808/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 809/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.8281 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 810/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6890 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 811/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.8246 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 812/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 0.8436 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 813/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.8065 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 814/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8344 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 815/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8265 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 816/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.8528 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 817/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.8322 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 818/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 819/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.8485 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 820/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.8120 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 821/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.8584 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 822/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6801 - loss: 0.8487 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 823/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.8284 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 824/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8416 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 825/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8313 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 826/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 827/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.8655 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 828/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.8472 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 829/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 830/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6969 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 831/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6828 - loss: 0.8439 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 832/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 833/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8276 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 834/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6977 - loss: 0.8229 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 835/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 0.8246 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 836/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8257 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 837/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.8304 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 838/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.8206 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 839/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7036 - loss: 0.8139 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 840/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 841/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.8403 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 842/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6942 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 843/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.8324 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 844/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.8418 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 845/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7051 - loss: 0.8120 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 846/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 847/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 848/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.8276 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 849/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 850/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.8417 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 851/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.8423 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 852/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 853/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6811 - loss: 0.8476 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 854/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 0.8192 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 855/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.8499 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 856/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.8143 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 857/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.8219 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 858/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.8319 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 859/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8337 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 860/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8398 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 861/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8258 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 862/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7002 - loss: 0.8186 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 863/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7057 - loss: 0.8114 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 864/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6853 - loss: 0.8409 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 865/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6744 - loss: 0.8568 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 866/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 0.8301 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 867/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7025 - loss: 0.8157 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 868/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6801 - loss: 0.8489 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 869/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7050 - loss: 0.8124 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 870/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8281 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 871/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.8469 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 872/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.8327 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 873/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 0.8218 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 874/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.8374 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 875/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.8439 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 876/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6975 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 877/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 878/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.8368 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 879/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6903 - loss: 0.8337 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 880/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6935 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 881/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.8376 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 882/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7022 - loss: 0.8159 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 883/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6890 - loss: 0.8354 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 884/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7040 - loss: 0.8136 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 885/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.8167 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 886/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.8179 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 887/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.8505 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 888/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.8216 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 889/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6935 - loss: 0.8291 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 890/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 891/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7034 - loss: 0.8138 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 892/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.8406 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 893/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7045 - loss: 0.8125 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 894/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.8362 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 895/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7005 - loss: 0.8190 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 896/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6902 - loss: 0.8337 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 897/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.8151 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 898/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.8118 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 899/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.8178 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 900/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.8175 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 901/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 902/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.8234 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 903/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7000 - loss: 0.8190 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 904/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.8412 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 905/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8389 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 906/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.8105 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 907/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7003 - loss: 0.8188 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 908/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.8341 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 909/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8354 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 910/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 0.8259 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 911/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 912/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8394 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 913/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.8278 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 914/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 915/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6963 - loss: 0.8243 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 916/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.8291 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 917/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 918/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.8197 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 919/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6856 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 920/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7025 - loss: 0.8156 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 921/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6805 - loss: 0.8484 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 922/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.8317 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 923/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8261 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 924/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6849 - loss: 0.8418 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 925/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8384 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 926/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.8406 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 927/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 928/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7031 - loss: 0.8143 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 929/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6755 - loss: 0.8565 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 930/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 0.8451 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 931/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6808 - loss: 0.8474 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 932/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.8409 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 933/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.8257 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 934/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.8427 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 935/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8346 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 936/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.8445 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 937/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.8284 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 938/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.8299 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 939/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8256 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 940/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6805 - loss: 0.8483 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 941/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6912 - loss: 0.8313 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 942/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6907 - loss: 0.8331 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 943/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6747 - loss: 0.8569 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 944/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.8215 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 945/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 0.8147 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 946/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6770 - loss: 0.8538 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 947/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6816 - loss: 0.8459 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 948/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6893 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 949/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.8545 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 950/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.8363 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 951/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8347 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 952/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8389 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 953/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.8321 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 954/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8354 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 955/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6815 - loss: 0.8467 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 956/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.8220 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 957/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6994 - loss: 0.8199 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 958/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6977 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 959/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.8206 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 960/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.8283 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 961/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6958 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 962/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.8553 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 963/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6826 - loss: 0.8447 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 964/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6826 - loss: 0.8460 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 965/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.8341 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 966/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 967/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.8523 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 968/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 969/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6943 - loss: 0.8277 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 970/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.8449 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 971/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6907 - loss: 0.8327 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 972/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 973/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.8132 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 974/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 975/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.8104 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 976/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.8388 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 977/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6904 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 978/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7124 - loss: 0.8006 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 979/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6847 - loss: 0.8414 - val_accuracy: 0.7052 - val_loss: 0.8114\n",
      "Epoch 980/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.8179 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 981/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.8445 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 982/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.8433 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 983/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8401 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 984/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 0.8429 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 985/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.8208 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 986/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 987/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6885 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 988/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.8495 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 989/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.8308 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 990/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8264 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 991/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 0.8437 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 992/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.8381 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 993/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 994/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8341 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 995/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.8445 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 996/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7057 - loss: 0.8112 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 997/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.8291 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 998/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8417 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 999/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1000/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8299 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1001/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.8280 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1002/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.8260 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1003/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1004/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6868 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 1005/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.8490 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1006/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8304 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1007/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.8010 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1008/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.8226 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1009/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6950 - loss: 0.8265 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1010/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.8169 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1011/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.8277 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1012/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8388 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1013/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6938 - loss: 0.8277 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1014/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.8242 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1015/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1016/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1017/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6995 - loss: 0.8199 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1018/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.8375 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1019/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.8425 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1020/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.8437 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1021/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7013 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1022/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: 0.8311 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1023/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.8395 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1024/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6906 - loss: 0.8336 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1025/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6909 - loss: 0.8329 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1026/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.8505 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1027/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.8145 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1028/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.8181 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1029/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.8208 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1030/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8330 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1031/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6922 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1032/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6864 - loss: 0.8389 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1033/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.8254 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1034/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.8228 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1035/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6933 - loss: 0.8294 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1036/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.8608 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1037/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6880 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1038/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.8396 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1039/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7042 - loss: 0.8128 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1040/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1041/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.8415 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1042/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.8247 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1043/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1044/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8282 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1045/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1046/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6801 - loss: 0.8487 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1047/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.8440 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1048/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8385 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1049/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6966 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1050/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.8364 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1051/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1052/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1053/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6888 - loss: 0.8356 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1054/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8314 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1055/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.8280 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1056/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8321 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1057/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6724 - loss: 0.8613 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1058/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6956 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1059/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6933 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1060/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.8282 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1061/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.8464 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1062/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.8253 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1063/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.8117 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1064/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6896 - loss: 0.8351 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1065/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1066/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.8417 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1067/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.8219 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1068/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.8413 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1069/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.8379 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1070/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.8428 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1071/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6959 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1072/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.8214 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1073/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6887 - loss: 0.8356 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1074/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.8183 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1075/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.8272 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1076/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.8497 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1077/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.8040 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1078/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.8259 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1079/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6948 - loss: 0.8267 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1080/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.8271 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1081/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6853 - loss: 0.8407 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1082/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.8207 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1083/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.8209 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1084/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 0.8512 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1085/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6880 - loss: 0.8365 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1086/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6996 - loss: 0.8200 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1087/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.8233 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1088/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.8242 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1089/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1090/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6784 - loss: 0.8517 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1091/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8393 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1092/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6849 - loss: 0.8425 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1093/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1094/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6942 - loss: 0.8273 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1095/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.8366 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1096/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1097/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.8145 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1098/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.8381 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1099/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.8249 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1100/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.8403 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1101/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.8244 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1102/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.8173 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1103/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.8283 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1104/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6968 - loss: 0.8240 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1105/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6853 - loss: 0.8405 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1106/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6881 - loss: 0.8370 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1107/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6873 - loss: 0.8385 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1108/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.8446 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1109/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6909 - loss: 0.8330 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1110/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6852 - loss: 0.8413 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1111/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.8170 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1112/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6864 - loss: 0.8400 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1113/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.8434 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1114/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.8251 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1115/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6961 - loss: 0.8247 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1116/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8421 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1117/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1118/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6961 - loss: 0.8252 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1119/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6812 - loss: 0.8472 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1120/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.8278 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1121/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.8290 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1122/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.8442 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1123/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6894 - loss: 0.8342 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1124/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.8289 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1125/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.8217 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1126/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6968 - loss: 0.8236 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1127/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.8440 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1128/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.8446 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1129/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.8305 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1130/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.8198 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1131/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.8201 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1132/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6890 - loss: 0.8359 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1133/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.8391 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1134/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.8444 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1135/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.8224 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1136/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6981 - loss: 0.8223 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1137/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8247 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1138/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.8213 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1139/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.8340 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1140/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.8380 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1141/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.8482 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1142/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.8292 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1143/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8238 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1144/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6997 - loss: 0.8200 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1145/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.8446 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1146/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.8380 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1147/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 0.8297 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1148/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.8295 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1149/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.8322 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1150/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.8294 - val_accuracy: 0.7052 - val_loss: 0.8107\n",
      "Epoch 1151/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.8425 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1152/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.8403 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1153/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.8348 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1154/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6931 - loss: 0.8291 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1155/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1156/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6978 - loss: 0.8230 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1157/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.8202 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1158/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8397 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1159/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.8180 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1160/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6902 - loss: 0.8338 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1161/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.8312 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1162/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6983 - loss: 0.8216 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1163/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6980 - loss: 0.8222 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 1164/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.8408 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1165/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.8075 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1166/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.8410 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1167/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1168/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.8334 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1169/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8096 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1170/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.8106 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1171/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6902 - loss: 0.8333 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1172/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.8339 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1173/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.8389 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1174/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8357 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1175/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6870 - loss: 0.8383 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1176/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.8418 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1177/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.8263 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1178/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.8457 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1179/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 0.8487 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1180/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.8382 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1181/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.8420 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1182/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1183/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.8241 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1184/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.8268 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1185/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6808 - loss: 0.8481 - val_accuracy: 0.7052 - val_loss: 0.8111\n",
      "Epoch 1186/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.8217 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1187/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.8374 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1188/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8352 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1189/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.8145 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1190/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8293 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1191/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6881 - loss: 0.8373 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1192/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.8287 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1193/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.8387 - val_accuracy: 0.7052 - val_loss: 0.8110\n",
      "Epoch 1194/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8333 - val_accuracy: 0.7052 - val_loss: 0.8108\n",
      "Epoch 1195/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.8197 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1196/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.8395 - val_accuracy: 0.7052 - val_loss: 0.8113\n",
      "Epoch 1197/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6800 - loss: 0.8490 - val_accuracy: 0.7052 - val_loss: 0.8112\n",
      "Epoch 1198/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.8316 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1199/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6976 - loss: 0.8225 - val_accuracy: 0.7052 - val_loss: 0.8109\n",
      "Epoch 1200/1200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.8253 - val_accuracy: 0.7052 - val_loss: 0.8110\n"
     ]
    }
   ],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, epochs=1200, batch_size=128, validation_data=(x_test, y_test))\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 97.4846785068512\n"
     ]
    }
   ],
   "source": [
    "print('Training time:', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7413209d0b30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - 2ms/step - accuracy: 0.7052 - loss: 0.8110\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "timestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "model.save(f'models/nn_{timestamp}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
